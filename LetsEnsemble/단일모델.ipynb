{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92d257cd-824a-4921-8b21-c14bada43824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/sarmat/lgbm-stacking-example/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1cc2c9a-80ee-4932-b759-7f49c34b9ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from dataset import custom_train_test_split, make_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84f4ceb8-7f94-43ca-90e5-1fa66095051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "param1 = {   \n",
    "            'boosting': 'gbdt',\n",
    "            'objective': 'binary',\n",
    "            'num_leaves' : 30,\n",
    "            'metric' : 'binary_logloss',\n",
    "            'learning_rate' : 0.001\n",
    "            \n",
    "            }\n",
    "\n",
    "param2 = {   \n",
    "            'boosting': 'gbdt',\n",
    "            'objective': 'binary',\n",
    "            'num_leaves' : 40,\n",
    "            'metric' : 'binary_logloss',\n",
    "            'learning_rate' : 0.001\n",
    "            }\n",
    "\n",
    "param3 = {   \n",
    "            'boosting': 'gbdt',\n",
    "            'objective': 'binary',\n",
    "            'num_leaves' : 48,\n",
    "            'metric' : 'binary_logloss',\n",
    "            'learning_rate' : 0.005\n",
    "            }\n",
    "\n",
    "param4 = {   \n",
    "            'boosting': 'gbdt',\n",
    "            'objective': 'binary',\n",
    "            'num_leaves' : 60,\n",
    "            'metric' : 'binary_logloss',\n",
    "            'learning_rate' : 0.005\n",
    "            }\n",
    "\n",
    "param5 = {   \n",
    "            'boosting': 'gbdt',\n",
    "            'objective': 'binary',\n",
    "            'num_leaves' : 70,\n",
    "            'metric' : 'binary_logloss',\n",
    "            'learning_rate' : 0.01\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee7f6473-3745-4b22-9fbd-f6dfe18b4a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['i_head', 'i_mid','i_tail', 'hour', 'dow']\n",
    "cont_cols = [                        \n",
    "        'user_correct_answer',\n",
    "        'user_total_answer',\n",
    "        'user_acc',            \n",
    "        't_elapsed',            \n",
    "        'cum_correct',\n",
    "        'last_problem',\n",
    "        'head_term',\n",
    "        # 'left_asymptote',\n",
    "        'elo_prob',\n",
    "        'pkt',\n",
    "        'u_head_mean',\n",
    "        'u_head_count',\n",
    "        'u_head_std',\n",
    "        'u_head_elapsed',\n",
    "        'i_mid_elapsed',\n",
    "        'i_mid_mean',\n",
    "        'i_mid_std',\n",
    "        'i_mid_sum',\n",
    "        'i_mid_count',\n",
    "        'i_mid_tag_count',\n",
    "        'assessment_mean',\n",
    "        'assessment_sum',\n",
    "        # 'assessment_std',\n",
    "        'tag_mean',\n",
    "        'tag_sum',\n",
    "        # 'tag_std',\n",
    "        'tail_mean',\n",
    "        'tail_sum',\n",
    "        # 'tail_std',\n",
    "        'hour_mean',\n",
    "        'hour_sum',\n",
    "        # 'hour_std',\n",
    "        'dow_mean',\n",
    "        'dow_sum',\n",
    "        # 'dow_std',\n",
    "        'tag_elapsed',\n",
    "        'tag_elapsed_o',\n",
    "        'tag_elapsed_x',\n",
    "        'assessment_elapsed',\n",
    "        'assessment_elapsed_o',\n",
    "        'assessment_elapsed_x',\n",
    "        'tail_elapsed',\n",
    "        'tail_elapsed_o',\n",
    "        'tail_elapsed_x']\n",
    "\n",
    "FEATS = cat_cols + cont_cols    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9884ba83-6b5d-425b-be04-c0000a1f3c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('/opt/ml/level2-dkt-level2-recsys-08/data_pkl/all.pkl')\n",
    "y = train.answerCode\n",
    "# train, test = custom_train_test_split(train_data)\n",
    "# y_train, train, y_test, test = make_dataset(train, test)\n",
    "test = pd.read_pickle('/opt/ml/level2-dkt-level2-recsys-08/data_pkl/test_data.pkl')\n",
    "test = test[test.answerCode==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c404f1b8-04c6-49bf-843b-3f3485fd513a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1102675, number of negative: 581295\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051052 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6624\n",
      "[LightGBM] [Info] Number of data points in the train set: 1683970, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654807 -> initscore=0.640236\n",
      "[LightGBM] [Info] Start training from score 0.640236\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.616366\n",
      "[200]\tvalid_0's binary_logloss: 0.593013\n",
      "[300]\tvalid_0's binary_logloss: 0.573518\n",
      "[400]\tvalid_0's binary_logloss: 0.557033\n",
      "[500]\tvalid_0's binary_logloss: 0.542937\n",
      "[600]\tvalid_0's binary_logloss: 0.530791\n",
      "[700]\tvalid_0's binary_logloss: 0.520344\n",
      "[800]\tvalid_0's binary_logloss: 0.511265\n",
      "[900]\tvalid_0's binary_logloss: 0.503352\n",
      "[1000]\tvalid_0's binary_logloss: 0.496379\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's binary_logloss: 0.496379\n",
      "[LightGBM] [Info] Number of positive: 1102675, number of negative: 581295\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6624\n",
      "[LightGBM] [Info] Number of data points in the train set: 1683970, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654807 -> initscore=0.640236\n",
      "[LightGBM] [Info] Start training from score 0.640236\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.615687\n",
      "[200]\tvalid_0's binary_logloss: 0.591841\n",
      "[300]\tvalid_0's binary_logloss: 0.571982\n",
      "[400]\tvalid_0's binary_logloss: 0.555236\n",
      "[500]\tvalid_0's binary_logloss: 0.540977\n",
      "[600]\tvalid_0's binary_logloss: 0.528583\n",
      "[700]\tvalid_0's binary_logloss: 0.517952\n",
      "[800]\tvalid_0's binary_logloss: 0.508767\n",
      "[900]\tvalid_0's binary_logloss: 0.50076\n",
      "[1000]\tvalid_0's binary_logloss: 0.493769\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's binary_logloss: 0.493769\n",
      "[LightGBM] [Info] Number of positive: 1102675, number of negative: 581295\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068464 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6624\n",
      "[LightGBM] [Info] Number of data points in the train set: 1683970, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654807 -> initscore=0.640236\n",
      "[LightGBM] [Info] Start training from score 0.640236\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.53961\n",
      "[200]\tvalid_0's binary_logloss: 0.492029\n",
      "[300]\tvalid_0's binary_logloss: 0.467224\n",
      "[400]\tvalid_0's binary_logloss: 0.453557\n",
      "[500]\tvalid_0's binary_logloss: 0.445695\n",
      "[600]\tvalid_0's binary_logloss: 0.440954\n",
      "[700]\tvalid_0's binary_logloss: 0.437873\n",
      "[800]\tvalid_0's binary_logloss: 0.435759\n",
      "[900]\tvalid_0's binary_logloss: 0.434261\n",
      "[1000]\tvalid_0's binary_logloss: 0.43313\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's binary_logloss: 0.43313\n",
      "[LightGBM] [Info] Number of positive: 1102675, number of negative: 581295\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044606 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6624\n",
      "[LightGBM] [Info] Number of data points in the train set: 1683970, number of used features: 43\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654807 -> initscore=0.640236\n",
      "[LightGBM] [Info] Start training from score 0.640236\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.538107\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=3, random_state = 42,shuffle = True)\n",
    "\n",
    "oof_clf1 = np.zeros(len(train))\n",
    "oof_clf2 = np.zeros(len(train))\n",
    "oof_clf3 = np.zeros(len(train))\n",
    "oof_clf4 = np.zeros(len(train))\n",
    "oof_clf5 = np.zeros(len(train))\n",
    "\n",
    "oof_clf1_t = np.zeros(len(test))\n",
    "oof_clf2_t = np.zeros(len(test))\n",
    "oof_clf3_t = np.zeros(len(test))\n",
    "oof_clf4_t = np.zeros(len(test))\n",
    "oof_clf5_t = np.zeros(len(test))\n",
    "\n",
    "for (trn_idx, val_idx),test_val_idx in zip(kf.split(train.values, y.values),kf.split(test.values)):\n",
    "        test_val_idx = test_val_idx[0]\n",
    "        # print(\"fold n°{}\".format(fold_))        \n",
    "        \n",
    "        lgb_train = lgb.Dataset(train[FEATS].iloc[trn_idx], label = y.iloc[trn_idx]) # lgb.Dataset(train[FEATS], y_train)\n",
    "        lgb_valid = lgb.Dataset(train[FEATS].iloc[val_idx], label = y.iloc[val_idx]) # lgb.Dataset(valid[FEATS], y_valid)\n",
    "        \n",
    "        model1 = lgb.train(param1, lgb_train, 1000, valid_sets=[lgb_valid], early_stopping_rounds=100,verbose_eval=100, categorical_feature = cat_cols)\n",
    "        model2 = lgb.train(param2, lgb_train, 1000, valid_sets=[lgb_valid], early_stopping_rounds=100,verbose_eval=100, categorical_feature = cat_cols)\n",
    "        model3 = lgb.train(param3, lgb_train, 1000, valid_sets=[lgb_valid], early_stopping_rounds=100,verbose_eval=100, categorical_feature = cat_cols)\n",
    "        model4 = lgb.train(param4, lgb_train, 1000, valid_sets=[lgb_valid], early_stopping_rounds=100,verbose_eval=100, categorical_feature = cat_cols)\n",
    "        model5 = lgb.train(param5, lgb_train, 1000, valid_sets=[lgb_valid], early_stopping_rounds=100,verbose_eval=100, categorical_feature = cat_cols)            \n",
    "        \n",
    "        oof_clf1[val_idx] = model1.predict(train[FEATS].iloc[val_idx])\n",
    "        oof_clf2[val_idx] = model2.predict(train[FEATS].iloc[val_idx])\n",
    "        oof_clf3[val_idx] = model3.predict(train[FEATS].iloc[val_idx])\n",
    "        oof_clf4[val_idx] = model4.predict(train[FEATS].iloc[val_idx])\n",
    "        oof_clf5[val_idx] = model5.predict(train[FEATS].iloc[val_idx])\n",
    "        \n",
    "        oof_clf1_t[test_val_idx] = model1.predict(test[FEATS].iloc[test_val_idx])\n",
    "        oof_clf2_t[test_val_idx] = model2.predict(test[FEATS].iloc[test_val_idx])\n",
    "        oof_clf3_t[test_val_idx] = model3.predict(test[FEATS].iloc[test_val_idx])\n",
    "        oof_clf4_t[test_val_idx] = model4.predict(test[FEATS].iloc[test_val_idx])\n",
    "        oof_clf5_t[test_val_idx] = model5.predict(test[FEATS].iloc[test_val_idx])\n",
    "        \n",
    "        # print('Fold no: {}'.format(fold_))\n",
    "        print(\"AUC LGB1:{} \".format(metrics.roc_auc_score(y.iloc[val_idx], oof_clf1[val_idx])))\n",
    "        print(\"AUC LGB2:{} \".format(metrics.roc_auc_score(y.iloc[val_idx], oof_clf2[val_idx])))\n",
    "        print(\"AUC LGB3:{} \".format(metrics.roc_auc_score(y.iloc[val_idx], oof_clf3[val_idx])))\n",
    "        print(\"AUC LGB4:{} \".format(metrics.roc_auc_score(y.iloc[val_idx], oof_clf4[val_idx])))\n",
    "        print(\"AUC LGB5:{} \".format(metrics.roc_auc_score(y.iloc[val_idx], oof_clf5[val_idx]))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa96f2b-c9b8-482e-9c5a-bf6d57f10479",
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_train = pd.DataFrame( {\n",
    "        'LGBM1': oof_clf1.ravel(),\n",
    "        'LGBM2': oof_clf2.ravel(),\n",
    "        'LGBM3': oof_clf3.ravel(),\n",
    "        'LGBM4' :oof_clf4.ravel(),\n",
    "        'LGBM5': oof_clf5.ravel(),\n",
    "    })\n",
    "\n",
    "Final_test = pd.DataFrame( {\n",
    "        'LGBM1': oof_clf1_t.ravel(),\n",
    "        'LGBM2': oof_clf2_t.ravel(),\n",
    "        'LGBM3': oof_clf3_t.ravel(),\n",
    "        'LGBM4' :oof_clf4_t.ravel(),\n",
    "        'LGBM5': oof_clf5_t.ravel(),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b5435a-ab5d-4f37-90d7-0655c15f2da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'objective': 'binary',\n",
    "                 'boosting': 'gbdt',\n",
    "                 'random_state': 42,\n",
    "                 'metric': 'auc',\n",
    "                 'num_threads': -1,\n",
    "                 'learning_rate' : 0.1,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8327116-8598-4455-b695-9d18c7e88675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1323032, number of negative: 697732\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1272\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020764, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654719 -> initscore=0.639846\n",
      "[LightGBM] [Info] Start training from score 0.639846\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's auc: 0.859143\n",
      "[200]\tvalid_0's auc: 0.859199\n",
      "[300]\tvalid_0's auc: 0.859203\n",
      "[400]\tvalid_0's auc: 0.859195\n",
      "Early stopping, best iteration is:\n",
      "[274]\tvalid_0's auc: 0.859209\n",
      "AUC LGB1:0.8592087895357379 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1322521, number of negative: 698244\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008123 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1274\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020765, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654466 -> initscore=0.638726\n",
      "[LightGBM] [Info] Start training from score 0.638726\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's auc: 0.859467\n",
      "[200]\tvalid_0's auc: 0.859548\n",
      "[300]\tvalid_0's auc: 0.859528\n",
      "[400]\tvalid_0's auc: 0.859508\n",
      "Early stopping, best iteration is:\n",
      "[203]\tvalid_0's auc: 0.859551\n",
      "AUC LGB1:0.8595507458839953 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1323005, number of negative: 697760\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008914 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020765, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654705 -> initscore=0.639786\n",
      "[LightGBM] [Info] Start training from score 0.639786\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's auc: 0.859134\n",
      "[200]\tvalid_0's auc: 0.859175\n",
      "[300]\tvalid_0's auc: 0.859167\n",
      "Early stopping, best iteration is:\n",
      "[192]\tvalid_0's auc: 0.859179\n",
      "AUC LGB1:0.8591785036297009 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1323025, number of negative: 697740\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020765, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654715 -> initscore=0.639830\n",
      "[LightGBM] [Info] Start training from score 0.639830\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's auc: 0.859408\n",
      "[200]\tvalid_0's auc: 0.859489\n",
      "[300]\tvalid_0's auc: 0.859496\n",
      "[400]\tvalid_0's auc: 0.859484\n",
      "Early stopping, best iteration is:\n",
      "[296]\tvalid_0's auc: 0.859499\n",
      "AUC LGB1:0.8594987951738651 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1322769, number of negative: 697996\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020990 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1273\n",
      "[LightGBM] [Info] Number of data points in the train set: 2020765, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654588 -> initscore=0.639269\n",
      "[LightGBM] [Info] Start training from score 0.639269\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's auc: 0.859492\n",
      "[200]\tvalid_0's auc: 0.859563\n",
      "[300]\tvalid_0's auc: 0.859566\n",
      "[400]\tvalid_0's auc: 0.859542\n",
      "Early stopping, best iteration is:\n",
      "[237]\tvalid_0's auc: 0.85957\n",
      "AUC LGB1:0.8595700525331934 \n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, random_state = 42,shuffle = True)\n",
    "\n",
    "Final_oof_train = np.zeros(len(train))\n",
    "Final_oof_test = np.zeros(len(test))\n",
    "\n",
    "for (trn_idx, val_idx), test_val_idx in zip(kf.split(Final_train.values, y.values), kf.split(Final_test.values)):\n",
    "        # print(\"fold n°{}\".format(fold_))\n",
    "        test_val_idx = test_val_idx[0]\n",
    "        lgb_train = lgb.Dataset(Final_train.iloc[trn_idx], label = y.iloc[trn_idx])\n",
    "        lgb_valid = lgb.Dataset(Final_train.iloc[val_idx], label = y.iloc[val_idx])\n",
    "        \n",
    "        model = lgb.train(param, lgb_train, 1000, valid_sets=[lgb_valid], early_stopping_rounds=200,verbose_eval=100)\n",
    "                \n",
    "        Final_oof_train[val_idx] = model.predict(Final_train.iloc[val_idx])        \n",
    "        \n",
    "        Final_oof_test[test_val_idx] = model.predict(Final_test.iloc[test_val_idx])\n",
    "        \n",
    "        # print('Fold no: {}'.format(fold_))\n",
    "        print(\"AUC LGB1:{} \".format(metrics.roc_auc_score(y.iloc[val_idx], Final_oof_train[val_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa5b7cd-378d-4a54-afb9-620b1681b01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35684508229113665"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_oof_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a99cb3-1a1c-48d4-82b0-652a4f385c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_to_csv(preds, name:str):\n",
    "    result = []\n",
    "    for n,i in enumerate(preds):\n",
    "        row = {}    \n",
    "        row['id'] = n\n",
    "        row['prediction'] = i\n",
    "        result.append(row)\n",
    "    pd.DataFrame(result).to_csv(f'output/{name}.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9d7861-8ecc-4520-81bf-6d930f32a634",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_to_csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/opt/ml/level2-dkt-level2-recsys-08/LetsEnsemble/단일모델.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22444b54227d/opt/ml/level2-dkt-level2-recsys-08/LetsEnsemble/%EB%8B%A8%EC%9D%BC%EB%AA%A8%EB%8D%B8.ipynb#ch0000011vscode-remote?line=0'>1</a>\u001b[0m test_to_csv(Final_oof_test,\u001b[39m'\u001b[39m\u001b[39mEnsemble\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_to_csv' is not defined"
     ]
    }
   ],
   "source": [
    "test_to_csv(Final_oof_test,'Ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bed2532",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
