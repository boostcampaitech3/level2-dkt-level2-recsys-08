{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92d257cd-824a-4921-8b21-c14bada43824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/sarmat/lgbm-stacking-example/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1cc2c9a-80ee-4932-b759-7f49c34b9ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from dataset import custom_train_test_split, make_dataset\n",
    "\n",
    "from sklearn.metrics import RocCurveDisplay, accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "\n",
    "\n",
    "def get_metric(targets, preds):\n",
    "    auc = roc_auc_score(targets, preds)\n",
    "    acc = accuracy_score(targets, np.where(preds >= 0.5, 1, 0))\n",
    "    precsion = precision_score(targets, np.where(preds >= 0.5, 1, 0))\n",
    "    recall = recall_score(targets, np.where(preds >= 0.5, 1, 0))\n",
    "    F1_score = f1_score(targets, np.where(preds >= 0.5, 1, 0))\n",
    "\n",
    "    print('auc :',auc)\n",
    "    print('acc :',acc)\n",
    "    print('precision :',precsion)\n",
    "    print('recall :',recall)\n",
    "\n",
    "def test_to_csv(preds, name:str):\n",
    "    \n",
    "    result = []\n",
    "    for n,i in enumerate(preds):\n",
    "        row = {}    \n",
    "        row['id'] = n\n",
    "        row['prediction'] = i\n",
    "        result.append(row)\n",
    "    pd.DataFrame(result).to_csv(f'output/{name}.csv', index=None)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbfda087",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/opt/ml/input/data/train_data.csv')\n",
    "test_data  = pd.read_csv('/opt/ml/input/data/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddcb5a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop_duplicates(subset = [\"userID\", \"assessmentItemID\"], keep = \"last\", inplace = True)\n",
    "train_data.drop(['Timestamp','testId','KnowledgeTag'], axis=1, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b5f7b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_train = train_data.pivot_table('answerCode', index='userID', columns='assessmentItemID')\n",
    "matrix_train.fillna(0.5, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c459f8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id2idx = {v:i for i,v in enumerate(matrix_train.index)}\n",
    "user_idx2id = {i:v for i,v in enumerate(matrix_train.index)}\n",
    "\n",
    "item_id2idx = {v:i for i,v in enumerate(matrix_train.columns)}\n",
    "item_idx2id = {i:v for i,v in enumerate(matrix_train.columns)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "713964ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(matrix, userid, itemid, user_id2idx, item_id2idx,n=12):\n",
    "    nmf = NMF(n_components=n, max_iter=1000)\n",
    "    X = matrix\n",
    "    nmf.fit(X)\n",
    "    X_pred = nmf.inverse_transform(nmf.transform(X))\n",
    "\n",
    "    ret = [X_pred[user_id2idx[u], item_id2idx[i]] for u,i in zip(userid, itemid)]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c404f1b8-04c6-49bf-843b-3f3485fd513a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 1000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 1000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 1000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 1000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 1000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 1000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 1000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 1000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 1000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 1000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 1000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 1000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 1000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 1000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 1000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 1000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 1000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 1000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc : 0.854055734166637\n",
      "acc : 0.8118275548486912\n",
      "precision : 0.8239003669083602\n",
      "recall : 0.9065997777043467\n",
      "AUC NMF1:None \n",
      "auc : 0.8589932043500832\n",
      "acc : 0.815870591338375\n",
      "precision : 0.827833509568762\n",
      "recall : 0.9077893598485987\n",
      "AUC NMF2:None \n",
      "auc : 0.8646303977703766\n",
      "acc : 0.8194963329225997\n",
      "precision : 0.8308695222730714\n",
      "recall : 0.9097059088587822\n",
      "AUC NMF3:None \n",
      "auc : 0.8698873724865015\n",
      "acc : 0.8232204931166024\n",
      "precision : 0.8338313978400115\n",
      "recall : 0.9119468893628526\n",
      "AUC NMF4:None \n",
      "auc : 0.8746891790692226\n",
      "acc : 0.826873791911565\n",
      "precision : 0.8365948043667066\n",
      "recall : 0.9143861335576317\n",
      "AUC NMF5:None \n",
      "auc : 0.8796837377871889\n",
      "acc : 0.8313577437730546\n",
      "precision : 0.8403632538646665\n",
      "recall : 0.9167833218180179\n",
      "AUC NMF6:None \n",
      "auc : 0.8836672438619616\n",
      "acc : 0.8345425699854734\n",
      "precision : 0.8430499950368925\n",
      "recall : 0.9184835831656103\n",
      "AUC NMF7:None \n",
      "auc : 0.8879641983171652\n",
      "acc : 0.8372156194270463\n",
      "precision : 0.8446883903428285\n",
      "recall : 0.9208927874072517\n",
      "AUC NMF8:None \n",
      "auc : 0.8920788191893629\n",
      "acc : 0.8400579488774373\n",
      "precision : 0.8472327248842254\n",
      "recall : 0.9221905133827991\n",
      "AUC NMF9:None \n"
     ]
    }
   ],
   "source": [
    "valid_user  = pd.read_csv('/opt/ml/input/data/cv_valid_data.csv').userID.unique()\n",
    "all_train = pd.read_csv('/opt/ml/input/data/all.csv')\n",
    "valid_data = all_train[all_train.userID.isin(valid_user)]\n",
    "userid = sorted(list(set([u for u in valid_data.userID])))\n",
    "user_id2idx_valid = {v:i for i,v in enumerate(userid)}\n",
    "\n",
    "matrix_valid = 0.5*np.ones((len(userid), len(item_id2idx)))\n",
    "for user,item,a in zip(valid_data.userID, valid_data.assessmentItemID, valid_data.answerCode):\n",
    "    user,item = user_id2idx_valid[user],item_id2idx[item]\n",
    "    matrix_valid[user,item] = a\n",
    "\n",
    "valid_predict1 = predict(matrix_valid, valid_data.userID, valid_data.assessmentItemID, user_id2idx_valid, item_id2idx, 20)\n",
    "valid_predict2 = predict(matrix_valid, valid_data.userID, valid_data.assessmentItemID, user_id2idx_valid, item_id2idx, 22)\n",
    "valid_predict3 = predict(matrix_valid, valid_data.userID, valid_data.assessmentItemID, user_id2idx_valid, item_id2idx, 24)\n",
    "valid_predict4 = predict(matrix_valid, valid_data.userID, valid_data.assessmentItemID, user_id2idx_valid, item_id2idx, 26)\n",
    "valid_predict5 = predict(matrix_valid, valid_data.userID, valid_data.assessmentItemID, user_id2idx_valid, item_id2idx, 28)\n",
    "valid_predict6 = predict(matrix_valid, valid_data.userID, valid_data.assessmentItemID, user_id2idx_valid, item_id2idx, 30)\n",
    "valid_predict7 = predict(matrix_valid, valid_data.userID, valid_data.assessmentItemID, user_id2idx_valid, item_id2idx, 32)\n",
    "valid_predict8 = predict(matrix_valid, valid_data.userID, valid_data.assessmentItemID, user_id2idx_valid, item_id2idx, 34)\n",
    "valid_predict9 = predict(matrix_valid, valid_data.userID, valid_data.assessmentItemID, user_id2idx_valid, item_id2idx, 36)\n",
    "\n",
    "# item_id2idx는 train에서 사용한 것을 다시 사용한다.\n",
    "test_data  = pd.read_csv('/opt/ml/input/data/test_data.csv')\n",
    "\n",
    "userid = sorted(list(set([u for u in test_data.userID])))\n",
    "user_id2idx_test = {v:i for i,v in enumerate(userid)}\n",
    "\n",
    "matrix_test = 0.5*np.ones((len(userid), len(item_id2idx)))\n",
    "for user,item,a in zip(test_data.userID, test_data.assessmentItemID, test_data.answerCode):\n",
    "    user,item = user_id2idx_test[user],item_id2idx[item]\n",
    "    if a<0:a=0.5\n",
    "    matrix_test[user,item] = a\n",
    "\n",
    "test_data = test_data[test_data.answerCode==-1]\n",
    "\n",
    "test_predict1 = predict(matrix_test, test_data.userID, test_data.assessmentItemID, user_id2idx_test, item_id2idx, 20)\n",
    "test_predict2 = predict(matrix_test, test_data.userID, test_data.assessmentItemID, user_id2idx_test, item_id2idx, 22)\n",
    "test_predict3 = predict(matrix_test, test_data.userID, test_data.assessmentItemID, user_id2idx_test, item_id2idx, 24)\n",
    "test_predict4 = predict(matrix_test, test_data.userID, test_data.assessmentItemID, user_id2idx_test, item_id2idx, 26)\n",
    "test_predict5 = predict(matrix_test, test_data.userID, test_data.assessmentItemID, user_id2idx_test, item_id2idx, 28)\n",
    "test_predict6 = predict(matrix_test, test_data.userID, test_data.assessmentItemID, user_id2idx_test, item_id2idx, 30)\n",
    "test_predict7 = predict(matrix_test, test_data.userID, test_data.assessmentItemID, user_id2idx_test, item_id2idx, 32)\n",
    "test_predict8 = predict(matrix_test, test_data.userID, test_data.assessmentItemID, user_id2idx_test, item_id2idx, 34)\n",
    "test_predict9 = predict(matrix_test, test_data.userID, test_data.assessmentItemID, user_id2idx_test, item_id2idx, 36)\n",
    "\n",
    "# print('Fold no: {}'.format(fold_))\n",
    "print(\"AUC NMF1:{} \".format(get_metric(valid_data.answerCode.to_numpy(), np.array(valid_predict1))))\n",
    "print(\"AUC NMF2:{} \".format(get_metric(valid_data.answerCode.to_numpy(), np.array(valid_predict2))))\n",
    "print(\"AUC NMF3:{} \".format(get_metric(valid_data.answerCode.to_numpy(), np.array(valid_predict3))))\n",
    "print(\"AUC NMF4:{} \".format(get_metric(valid_data.answerCode.to_numpy(), np.array(valid_predict4))))\n",
    "print(\"AUC NMF5:{} \".format(get_metric(valid_data.answerCode.to_numpy(), np.array(valid_predict5)))) \n",
    "print(\"AUC NMF6:{} \".format(get_metric(valid_data.answerCode.to_numpy(), np.array(valid_predict6)))) \n",
    "print(\"AUC NMF7:{} \".format(get_metric(valid_data.answerCode.to_numpy(), np.array(valid_predict7)))) \n",
    "print(\"AUC NMF8:{} \".format(get_metric(valid_data.answerCode.to_numpy(), np.array(valid_predict8)))) \n",
    "print(\"AUC NMF9:{} \".format(get_metric(valid_data.answerCode.to_numpy(), np.array(valid_predict9)))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a496d655",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_valid = np.array([valid_predict1, valid_predict2, valid_predict3, valid_predict4, valid_predict5, valid_predict6, valid_predict7, valid_predict8, valid_predict9]).T\n",
    "\n",
    "new_test = np.array([test_predict1, test_predict2, test_predict3, test_predict4, test_predict5, test_predict6, test_predict7, test_predict8, test_predict9]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f9e5fd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.read_csv('/opt/ml/input/data/cv_valid_data.csv')\n",
    "tail_idx = val.index[val.answerCode==-1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "106ded69",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = valid_data.answerCode.to_numpy()\n",
    "\n",
    "valid_tail = [new_valid[i] for i in range(len(new_valid)) if i in tail_idx]\n",
    "y_tail = [y_valid[i] for i in range(len(y_valid)) if i in tail_idx]\n",
    "\n",
    "new_valid = [new_valid[i] for i in range(len(new_valid)) if not i in tail_idx]\n",
    "y_new_valid = [y_valid[i] for i in range(len(y_valid)) if not i in tail_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fae54566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24ff70a863c4babb1eb078a25dc71b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fbb2908c910>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "train_pool = Pool(new_valid, y_new_valid)\n",
    "# eval_pool = Pool(valid_tail , y_tail)\n",
    "eval_pool = Pool(valid_tail, y_tail)\n",
    "\n",
    "Final_cat = CatBoostClassifier(\n",
    "            iterations = 500,\n",
    "            random_seed = 42,\n",
    "            learning_rate = 0.01,\n",
    "            loss_function = 'Logloss', \n",
    "            custom_metric = ['Logloss','AUC'],\n",
    "            early_stopping_rounds = 30,\n",
    "            use_best_model =  True,\n",
    "            task_type = \"GPU\",\n",
    "            bagging_temperature = 1,\n",
    "            verbose = False)\n",
    "\n",
    "Final_cat.fit(train_pool, eval_set=eval_pool, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7d8210eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc : 0.8681234100370027\n",
      "acc : 0.7970430107526881\n",
      "precision : 0.7956403269754768\n",
      "recall : 0.7934782608695652\n"
     ]
    }
   ],
   "source": [
    "preds = Final_cat.predict(new_test , prediction_type='Probability')[:,1]\n",
    "val_preds = Final_cat.predict(valid_tail , prediction_type='Probability')[:,1]\n",
    "\n",
    "get_metric(y_tail, val_preds)\n",
    "\n",
    "from datetime import date, datetime, timezone, timedelta\n",
    "\n",
    "KST = timezone(timedelta(hours=9))\n",
    "time_record = datetime.now(KST)\n",
    "_day = str(time_record)[:10]\n",
    "_time = str(time_record.time())[:8]\n",
    "now_time = _day+'_'+_time\n",
    "\n",
    "test_to_csv(new_test.mean(axis=1),f'Stacking_NMF_{now_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fd3c913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_to_csv( new_test[:,0], 'NMF_38')\n",
    "test_to_csv( new_test[:,1], 'NMF_40')\n",
    "test_to_csv( new_test[:,2], 'NMF_42')\n",
    "test_to_csv( new_test[:,3], 'NMF_44')\n",
    "test_to_csv( new_test[:,4], 'NMF_46')\n",
    "test_to_csv( new_test[:,5], 'NMF_48')\n",
    "test_to_csv( new_test[:,6], 'NMF_50')\n",
    "test_to_csv( new_test[:,7], 'NMF_52')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae3a7e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "744"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e2fe59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
